{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vcli52GSxvNB"
      },
      "outputs": [],
      "source": [
        "from torchvision.models import resnet50 as _resnet50, ResNet50_Weights\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "\n",
        "# creating a function for model inferencing  :\n",
        "def resnet50(**kwargs):\n",
        "    \"\"\" # This docstring shows up in hub.help()\n",
        "    Resnet18 model\n",
        "    pretrained (bool): kwargs, load pretrained weights into the model\n",
        "    \"\"\"\n",
        "    # Call the model, load pretrained weights\n",
        "    model = _resnet50(weights=ResNet50_Weights.IMAGENET1K_V1, **kwargs)\n",
        "    return model\n",
        "convert_tensor = transforms.ToTensor()\n",
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "# Step 1: Initialize model with the best available weights\n",
        "weights = ResNet50_Weights.DEFAULT\n",
        "\n",
        "# Inference\n",
        "model = resnet50()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVt9R4GndW2w"
      },
      "source": [
        "Reading the video and saving its frames. The video used is in the link below:\n",
        "https://www.youtube.com/shorts/ara-UQzTkk4\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eWYFPAzB2O66"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "# Reading the video\n",
        "vidcap = cv2.VideoCapture('/path/to/video.mp4')\n",
        "# reading each frame as an image\n",
        "success,image = vidcap.read()\n",
        "# initialising the count of frames\n",
        "count = 0\n",
        "# The frame must be read successfully before we can proceed with saving it\n",
        "while success:\n",
        "  # save frame as JPEG file \n",
        "  cv2.imwrite(\"frame%d.jpg\" % count, image)          \n",
        "  success,image = vidcap.read()\n",
        "  #print('Read a new frame: ', success)\n",
        "  count += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5EQD3HCP8g2"
      },
      "source": [
        "Inference ResNet50 on the video and saving the results in the directory test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "S9uHTUgjYV_L"
      },
      "outputs": [],
      "source": [
        "from torchvision.io import read_image\n",
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "# Step 1: Initialize model with the best available weights\n",
        "model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
        "model.eval()\n",
        "# creating a directory named test to store the results \n",
        "!mkdir test \n",
        "\n",
        "for i in range (0,count):\n",
        "  # reading the images one by one\n",
        "  img = read_image(f'/content/frame{i}.jpg')\n",
        "  # using the open cv read to plot the images\n",
        "  plot_image = cv2.imread(f'/content/frame{i}.jpg')\n",
        "  #Image.open(f'/content/frame{i}.jpg')\n",
        "  #ploting the figure\n",
        "  plt.figure()\n",
        "  plt.imshow(plot_image)\n",
        "  # Step 2: Initialize the inference transforms\n",
        "  preprocess = weights.transforms()\n",
        "  # Step 3: Apply inference preprocessing transforms\n",
        "  batch = preprocess(img).unsqueeze(0)\n",
        "\n",
        "  # Step 4: Use the model and print the predicted category\n",
        "  prediction = model(batch).squeeze(0).softmax(0)\n",
        "  class_id = prediction.argmax().item()\n",
        "  score = prediction[class_id].item()\n",
        "  category_name = weights.meta[\"categories\"][class_id]\n",
        "  # Puting text on top of the image\n",
        "  cv2.putText(img=plot_image, text=f\"{category_name}: {100 * score:.1f}%\",org=(10, 50), fontFace=cv2.FONT_HERSHEY_DUPLEX, fontScale=0.8, color=(0,0,255), thickness=2)\n",
        "  # saving the images in the test directory\n",
        "  cv2.imwrite(f\"/content/test/frame_estimation{i}.jpg\", plot_image)\n",
        "  plt.title(f\"{category_name}: {100 * score:.1f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQk6G_Al7ejp"
      },
      "outputs": [],
      "source": [
        "# zipping the test file that contains images \n",
        "!zip -r /content/test /content/test\n",
        "# After zipping the file download it"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}